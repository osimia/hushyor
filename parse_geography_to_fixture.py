#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏ (A3-2_Geography_tj.pdf –∏ A3-2_Geography_tj_key.pdf)
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—É –∂–µ –ª–æ–≥–∏–∫—É —á—Ç–æ –∏ –¥–ª—è —Ç–∞–¥–∂–∏–∫—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
"""

import re
import json
import subprocess
from collections import deque
from typing import NamedTuple

# –ú–∞–ø–ø–∏–Ω–≥ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏—Ö –±—É–∫–≤ –≤ –ª–∞—Ç–∏–Ω—Å–∫–∏–µ
_CYR_TO_LAT = {
    '–ê': 'A', '–í': 'B', '–°': 'C', 'D': 'D',
    '–∞': 'A', '–≤': 'B', '—Å': 'C', 'd': 'D',
}

# –ú–∞–ø–ø–∏–Ω–≥ –±—É–∫–≤ –≤ —Ü–∏—Ñ—Ä—ã (1-4)
_LETTER_TO_NUMBER = {
    'A': '1', 'B': '2', 'C': '3', 'D': '4',
}


class ParsedTask(NamedTuple):
    number: int
    question: str
    options: dict[str, str]
    topic: str


def _normalize_space(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤"""
    return re.sub(r'\s+', ' ', text).strip()


def _is_topic_line(line: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º —Ç–µ–º—ã"""
    # –¢–µ–º—ã –æ–±—ã—á–Ω–æ –Ω–∞–ø–∏—Å–∞–Ω—ã –∑–∞–≥–ª–∞–≤–Ω—ã–º–∏ –±—É–∫–≤–∞–º–∏
    if not line:
        return False
    
    # –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–º –∏–∑ –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏
    topic_patterns = [
        r'^–ì–ï–û–ì–†–ê–§–ò–Ø–ò –¢–ê–ë–ò–ò–ò –£–ú–£–ú”¢',
        r'^–ì–ï–û–ì–†–ê–§–ò–Ø–ò',
        r'^[–ê-–Ø–Å\s]{10,}$',  # –°—Ç—Ä–æ–∫–∞ –∏–∑ –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –±—É–∫–≤
    ]
    
    for pattern in topic_patterns:
        if re.match(pattern, line):
            return True
    
    return False


def _is_question_number_line(line: str) -> int | None:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–æ–º–µ—Ä–æ–º –≤–æ–ø—Ä–æ—Å–∞"""
    # –ù–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞ - —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ
    if re.fullmatch(r'\d{1,4}', line):
        return int(line)
    return None


def _is_option_line(line: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–º –æ—Ç–≤–µ—Ç–∞"""
    # –í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å A), B), C), D)
    return bool(re.match(r'^\s*[ABCD–ê–í–°Dabcd]\)', line))


def parse_geography_tasks(tasks_text: str) -> list[ParsedTask]:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ Geography_tj.pdf
    
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
    - –¢–µ–º—ã (–∑–∞–≥–æ–ª–æ–≤–∫–∏ –∑–∞–≥–ª–∞–≤–Ω—ã–º–∏ –±—É–∫–≤–∞–º–∏)
    - –ù–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞ (—á–∏—Å–ª–æ) –ò–õ–ò –≤–æ–ø—Ä–æ—Å –±–µ–∑ –Ω–æ–º–µ—Ä–∞ (–ø–µ—Ä–≤—ã–π –ø–æ—Å–ª–µ —Ç–µ–º—ã)
    - –¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞ (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫)
    - –í–∞—Ä–∏–∞–Ω—Ç—ã A), B), C), D)
    """
    lines = [ln.rstrip() for ln in tasks_text.splitlines()]
    
    tasks: list[ParsedTask] = []
    current_topic: str | None = None
    question_counter = 1  # –°—á–µ—Ç—á–∏–∫ –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –±–µ–∑ –Ω–æ–º–µ—Ä–∞
    
    i = 0
    while i < len(lines):
        raw = lines[i]
        line = _normalize_space(raw)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
        if not line or line in ['.tj', '—Å–æ –†–û', '–º–æ –ô', '–Ω–∞ –ì –û', '–∏ –ù', 'w !', 'w', '.n', 'tc', '–î–∞', '—Ä']:
            i += 1
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü
        if '–ì–µ–æ–≥—Ä–∞—Ñ–∏—è' in line or '–°–∞“≥–∏—Ñ–∞–∏' in line or '–ò–ú–î 2025' in line or '–ù–ê–ú–£–ù–ê–ò' in line or '–°–ê–í–û–õ–£' in line:
            i += 1
            continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–µ–º—É
        if _is_topic_line(line):
            current_topic = line
            i += 1
            
            # –ü–æ—Å–ª–µ —Ç–µ–º—ã –º–æ–∂–µ—Ç –∏–¥—Ç–∏ –≤–æ–ø—Ä–æ—Å –ë–ï–ó –Ω–æ–º–µ—Ä–∞
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏
            if i < len(lines):
                next_line = _normalize_space(lines[i])
                # –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–µ —á–∏—Å–ª–æ –∏ –Ω–µ –ø—É—Å—Ç–∞—è - —ç—Ç–æ –≤–æ–ø—Ä–æ—Å –±–µ–∑ –Ω–æ–º–µ—Ä–∞
                if next_line and not re.fullmatch(r'\d{1,4}', next_line) and not next_line in ['.tj', '—Å–æ –†–û', '–º–æ –ô', '–Ω–∞ –ì –û', '–∏ –ù', 'w !', 'w', '.n', 'tc', '–î–∞', '—Ä']:
                    # –≠—Ç–æ –≤–æ–ø—Ä–æ—Å –±–µ–∑ –Ω–æ–º–µ—Ä–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—á–µ—Ç—á–∏–∫
                    number = question_counter
                    question_counter += 1
                    
                    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞
                    q_lines: list[str] = []
                    while i < len(lines):
                        l = _normalize_space(lines[i])
                        
                        if not l or l in ['.tj', '—Å–æ –†–û', '–º–æ –ô', '–Ω–∞ –ì –û', '–∏ –ù', 'w !', 'w', '.n', 'tc', '–î–∞', '—Ä']:
                            i += 1
                            continue
                        
                        if _is_option_line(l):
                            break
                        
                        if _is_topic_line(l):
                            break
                        
                        # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —á–∏—Å–ª–æ - —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å
                        if re.fullmatch(r'\d{1,4}', l):
                            break
                        
                        q_lines.append(l)
                        i += 1
                    
                    question = _normalize_space(" ".join(q_lines))
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã
                    options: dict[str, str] = {}
                    for _ in range(10):
                        if i >= len(lines):
                            break
                        
                        lraw = lines[i]
                        l = _normalize_space(lraw)
                        
                        if not l or l in ['.tj', '—Å–æ –†–û', '–º–æ –ô', '–Ω–∞ –ì –û', '–∏ –ù', 'w !', 'w', '.n', 'tc', '–î–∞', '—Ä']:
                            i += 1
                            continue
                        
                        m = re.match(r'^\s*([ABCD–ê–í–°Dabcd])\)\s*(.+)$', lraw)
                        if m:
                            letter = m.group(1).upper()
                            letter = _CYR_TO_LAT.get(letter, letter)
                            if letter in ('A', 'B', 'C', 'D'):
                                options[_LETTER_TO_NUMBER[letter]] = _normalize_space(m.group(2))
                            i += 1
                            if len(options) == 4:
                                break
                            continue
                        
                        # –ù–µ –≤–∞—Ä–∏–∞–Ω—Ç - –≤—ã—Ö–æ–¥–∏–º
                        if not _is_option_line(l):
                            break
                        i += 1
                    
                    if question and len(options) == 4:
                        tasks.append(ParsedTask(
                            number=number,
                            question=question,
                            options=options,
                            topic=current_topic or "–ì–µ–æ–≥—Ä–∞—Ñ–∏—è",
                        ))
            continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞
        num_only = _is_question_number_line(line)
        if num_only is not None:
            number = num_only
            question_counter = number + 1  # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫
            i += 1
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞ –¥–æ –ø–µ—Ä–≤–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
            q_lines: list[str] = []
            while i < len(lines):
                l = _normalize_space(lines[i])
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                if not l or l in ['.tj', '—Å–æ –†–û', '–º–æ –ô', '–Ω–∞ –ì –û', '–∏ –ù', 'w !', 'w', '.n', 'tc', '–î–∞', '—Ä']:
                    i += 1
                    continue
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞ - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
                if _is_option_line(l):
                    break
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –Ω–æ–≤—É—é —Ç–µ–º—É
                if _is_topic_line(l):
                    current_topic = l
                    i += 1
                    continue
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –Ω–æ–º–µ—Ä —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
                if re.fullmatch(r'\d{1,4}', l):
                    break
                
                q_lines.append(l)
                i += 1
            
            question = _normalize_space(" ".join(q_lines))
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
            options: dict[str, str] = {}
            for _ in range(15):  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–æ–ø—ã—Ç–∫–∏
                if i >= len(lines):
                    break
                
                lraw = lines[i]
                l = _normalize_space(lraw)
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                if not l or l in ['.tj', '—Å–æ –†–û', '–º–æ –ô', '–Ω–∞ –ì –û', '–∏ –ù', 'w !', 'w', '.n', 'tc', '–î–∞', '—Ä']:
                    i += 1
                    continue
                
                # –ü–∞—Ä—Å–∏–º –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞
                m = re.match(r'^\s*([ABCD–ê–í–°Dabcd])\)\s*(.+)$', lraw)
                if m:
                    letter = m.group(1).upper()
                    letter = _CYR_TO_LAT.get(letter, letter)
                    if letter in ('A', 'B', 'C', 'D'):
                        options[_LETTER_TO_NUMBER[letter]] = _normalize_space(m.group(2))
                    i += 1
                    if len(options) == 4:
                        break
                    continue
                
                # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Å–ª–∏—Ç–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
                m2 = re.match(r'^\s*([ABCD–ê–í–°Dabcd])\)\s*(.+)$', l)
                if m2:
                    letter = m2.group(1).upper()
                    letter = _CYR_TO_LAT.get(letter, letter)
                    if letter in ('A', 'B', 'C', 'D'):
                        options[_LETTER_TO_NUMBER[letter]] = _normalize_space(m2.group(2))
                    i += 1
                    if len(options) == 4:
                        break
                    continue
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –Ω–æ–º–µ—Ä —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ - –≤—ã—Ö–æ–¥–∏–º
                if re.fullmatch(r'\d{1,4}', l):
                    break
                
                # –ù–µ –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                i += 1
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–¥–∞—á—É –µ—Å–ª–∏ –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å –∏ 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞
            if question and len(options) == 4:
                tasks.append(ParsedTask(
                    number=number,
                    question=question,
                    options=options,
                    topic=current_topic or "–ì–µ–æ–≥—Ä–∞—Ñ–∏—è",
                ))
            continue
        
        i += 1
    
    return tasks


def parse_geography_answers(answers_text: str) -> dict[int, str]:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ Geography_tj_key.pdf
    
    –§–æ—Ä–º–∞—Ç:
    77  C
    78  C
    79  A
    ...
    """
    answers: dict[int, str] = {}
    pending_numbers: deque[int] = deque()
    
    lines = [re.sub(r'\s+', ' ', ln).strip() for ln in answers_text.splitlines()]
    
    # –ò—â–µ–º –Ω–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–æ–≤ (–ø–æ—Å–ª–µ "–ö–ê–õ–ò–î“≤–û–ò")
    start_idx = 0
    for idx, line in enumerate(lines):
        if '–ö–ê–õ–ò–î“≤–û–ò' in line or '–î–£–†–£–°–¢' in line:
            start_idx = idx + 1
            break
    
    lines = lines[start_idx:]
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
    patterns = [
        re.compile(r'^(\d{1,4})\s*[.)\-:]\s*([ABCD–ê–í–°Dabcd])$'),
        re.compile(r'^(\d{1,4})\s+([ABCD–ê–í–°Dabcd])$'),
    ]
    
    for line in lines:
        if not line or line in ['.tj', '—Å–æ –†–û', '–º–æ –ô', '–Ω–∞ –ì –û', '–∏ –ù', 'w !', 'w', '.n', 'tc', '–î–∞', '—Ä']:
            continue
        
        # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç "–Ω–æ–º–µ—Ä –±—É–∫–≤–∞"
        for pat in patterns:
            m = pat.match(line)
            if m:
                n = int(m.group(1))
                letter = m.group(2).upper()
                letter = _CYR_TO_LAT.get(letter, letter)
                if letter in _LETTER_TO_NUMBER:
                    answers[n] = _LETTER_TO_NUMBER[letter]
                break
        else:
            # –§–æ—Ä–º–∞—Ç —Å –æ—á–µ—Ä–µ–¥—å—é: —Å–Ω–∞—á–∞–ª–∞ –Ω–æ–º–µ—Ä–∞, –ø–æ—Ç–æ–º –±—É–∫–≤—ã
            if re.fullmatch(r'\d{1,4}', line):
                pending_numbers.append(int(line))
                continue
            
            if re.fullmatch(r'[ABCD–ê–í–°D]', line):
                if pending_numbers:
                    n = pending_numbers.popleft()
                    letter = _CYR_TO_LAT.get(line.upper(), line.upper())
                    if letter in _LETTER_TO_NUMBER:
                        answers[n] = _LETTER_TO_NUMBER[letter]
                continue
    
    return answers


def generate_fixture(tasks: list[ParsedTask], answers: dict[int, str]) -> list[dict]:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Django fixture –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
    
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
    - Subject: –ì–µ–æ–≥—Ä–∞—Ñ–∏—è (id=5)
    - Topics: –ø–æ —Ç–µ–º–∞–º –∏–∑ PDF
    - Tasks: –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã —Å –æ—Ç–≤–µ—Ç–∞–º–∏
    """
    fixture = []
    
    # 1. –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–¥–º–µ—Ç "–ì–µ–æ–≥—Ä–∞—Ñ–∏—è"
    subject_id = 5  # ID –¥–ª—è –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏
    fixture.append({
        "model": "core.subject",
        "pk": subject_id,
        "fields": {
            "title": "–ì–µ–æ–≥—Ä–∞—Ñ–∏—è",
            "icon": "üåç",
            "color": "#10B981"
        }
    })
    
    # 2. –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–º—ã
    topics_map: dict[str, int] = {}
    topic_pk = 50  # –ù–∞—á–∞–ª—å–Ω—ã–π ID –¥–ª—è —Ç–µ–º –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏
    
    for task in tasks:
        if task.topic and task.topic not in topics_map:
            topics_map[task.topic] = topic_pk
            fixture.append({
                "model": "core.topic",
                "pk": topic_pk,
                "fields": {
                    "subject": subject_id,
                    "title": task.topic,
                    "order": len(topics_map),
                    "is_locked": False
                }
            })
            topic_pk += 1
    
    # 3. –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏
    task_pk = 5000  # –ù–∞—á–∞–ª—å–Ω—ã–π ID –¥–ª—è –∑–∞–¥–∞—á –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏
    
    for task in tasks:
        correct_answer = answers.get(task.number)
        if not correct_answer:
            print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ {task.number}")
            continue
        
        topic_id = topics_map.get(task.topic)
        
        fixture.append({
            "model": "core.task",
            "pk": task_pk,
            "fields": {
                "subject": subject_id,
                "topic": topic_id,
                "question": task.question,
                "options": task.options,
                "correct_answer": correct_answer,
                "difficulty": 1,
                "order": task.number
            }
        })
        task_pk += 1
    
    return fixture


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üåç –ü–∞—Ä—Å–∏–Ω–≥ –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏...")
    print()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ PDF
    print("üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Geography_tj.pdf...")
    tasks_text = subprocess.check_output(
        ['pdftotext', 'A3-2_Geography_tj.pdf', '-'],
        text=True
    )
    
    print("üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Geography_tj_key.pdf...")
    answers_text = subprocess.check_output(
        ['pdftotext', 'A3-2_Geography_tj_key.pdf', '-'],
        text=True
    )
    
    # –ü–∞—Ä—Å–∏–º
    print("\nüîç –ü–∞—Ä—Å–∏–Ω–≥ –≤–æ–ø—Ä–æ—Å–æ–≤...")
    tasks = parse_geography_tasks(tasks_text)
    print(f"   –ù–∞–π–¥–µ–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(tasks)}")
    
    print("\nüîç –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤...")
    answers = parse_geography_answers(answers_text)
    print(f"   –ù–∞–π–¥–µ–Ω–æ –æ—Ç–≤–µ—Ç–æ–≤: {len(answers)}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–º–∞–º
    topics_count: dict[str, int] = {}
    for task in tasks:
        topics_count[task.topic] = topics_count.get(task.topic, 0) + 1
    
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–º–∞–º:")
    for topic, count in topics_count.items():
        print(f"   {topic}: {count} –≤–æ–ø—Ä–æ—Å–æ–≤")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º fixture
    print("\nüì¶ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è fixture...")
    fixture = generate_fixture(tasks, answers)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    output_file = "geography_data.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(fixture, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! Fixture —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_file}")
    print(f"   –ü—Ä–µ–¥–º–µ—Ç–æ–≤: 1")
    print(f"   –¢–µ–º: {len(topics_count)}")
    print(f"   –ó–∞–¥–∞—á: {len([item for item in fixture if item['model'] == 'core.task'])}")
    print()
    print("üì• –î–ª—è –∏–º–ø–æ—Ä—Ç–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
    print(f"   python manage.py loaddata {output_file}")


if __name__ == '__main__':
    main()
