#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–æ–≥–∏–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞ —Ç–∞–¥–∂–∏–∫—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
"""

from __future__ import annotations

import json
import re
import subprocess
from collections import deque
from dataclasses import dataclass
from pathlib import Path


@dataclass
class ParsedTask:
    number: int
    question: str
    options: dict[str, str]  # 1/2/3/4
    topic: str


_CYR_TO_LAT = {"–ê": "A", "–í": "B", "–°": "C", "D": "D"}
_LETTER_TO_NUMBER = {"A": "1", "B": "2", "C": "3", "D": "4"}


def run_pdftotext(pdf_path: Path, use_layout: bool = True) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF"""
    cmd = ["pdftotext"]
    if use_layout:
        cmd.append("-layout")
    cmd.extend([str(pdf_path), "-"])
    proc = subprocess.run(cmd, check=False, capture_output=True, text=True)
    if proc.returncode != 0:
        raise RuntimeError(f"pdftotext failed: {proc.stderr}")
    return proc.stdout or ""


def normalize_space(s: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤"""
    return re.sub(r"\s+", " ", s).strip()


def is_option_line(line: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–º –æ—Ç–≤–µ—Ç–∞"""
    return bool(re.match(r"^\s*[ABCD–ê–í–°Dabcd]\)\s+", line))


def is_question_number_line(line: str) -> int | None:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–æ–º–µ—Ä–æ–º –≤–æ–ø—Ä–æ—Å–∞"""
    m = re.match(r"^\s*(\d{1,4})\s*$", line)
    if not m:
        return None
    return int(m.group(1))


def match_question_start(line: str) -> tuple[int, str] | None:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞: '1    –í–æ–ø—Ä–æ—Å —Ç–µ–∫—Å—Ç?'"""
    m = re.match(r"^\s*(\d{1,4})\s{1,}(.*\S.*)$", line)
    if not m:
        return None
    return int(m.group(1)), normalize_space(m.group(2))


def extract_options_from_raw_line(raw: str) -> tuple[str, dict[str, str]]:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Å inline –æ–ø—Ü–∏—è–º–∏
    –ù–∞–ø—Ä–∏–º–µ—Ä: '1   –í–æ–ø—Ä–æ—Å?        –ê) –≤–∞—Ä–∏–∞–Ω—Ç'
    """
    options: dict[str, str] = {}
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –±–æ–ª—å—à–∏–º –ø—Ä–æ–±–µ–ª–∞–º (inline –∫–æ–ª–æ–Ω–∫–∏)
    parts = re.split(r"\s{2,}", raw.strip())
    kept_parts: list[str] = []
    
    for part in parts:
        m = re.match(r"^\s*([ABCD–ê–í–°Dabcd])\)\s*(.+)$", part)
        if m:
            letter = m.group(1).upper()
            letter = _CYR_TO_LAT.get(letter, letter)
            if letter in ("A", "B", "C", "D"):
                options[_LETTER_TO_NUMBER[letter]] = normalize_space(m.group(2))
            continue
        
        kept_parts.append(part)
    
    cleaned = normalize_space(" ".join(kept_parts))
    return cleaned, options


def is_topic_line(line: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º —Ç–µ–º—ã"""
    if not line:
        return False
    if is_option_line(line):
        return False
    if re.match(r"^\d+\b", line):
        return False
    
    # –°–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
    noisy = {
        ".tj", "—Å–æ –†–û", "–º–æ –ô", "–Ω–∞ –ì –û", "–∏ –ù", "w !", "w", ".n", "tc", "–î–∞", "—Ä",
        "–ì–µ–æ–≥—Ä–∞—Ñ–∏—è", "–°–∞“≥–∏—Ñ–∞–∏", "–ò–ú–î 2025", "–ù–ê–ú–£–ù–ê–ò", "–°–ê–í–û–õ–£", "–ú–ê–°–™–ê–õ–ê“≤–û",
        "–ë–û –ò–ù–¢–ò–•–û–ë–ò –Ø–ö “∂–ê–í–û–ë–ò –î–£–†–£–°–¢"
    }
    
    for noise in noisy:
        if noise in line:
            return False
    
    # –¢–µ–º—ã –æ–±—ã—á–Ω–æ –∑–∞–≥–ª–∞–≤–Ω—ã–º–∏ –±—É–∫–≤–∞–º–∏ –∏ –¥–ª–∏–Ω–Ω—ã–µ
    if len(line) > 15 and line.isupper():
        return True
    
    # –ò–ª–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    topic_keywords = ["–ì–ï–û–ì–†–ê–§–ò–Ø–ò", "–ì–ï–û–ì–†–ê–§–ò–Ø"]
    for kw in topic_keywords:
        if kw in line:
            return True
    
    return False


def parse_geography_tasks(text: str) -> list[ParsedTask]:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ Geography_tj.pdf
    
    –õ–æ–≥–∏–∫–∞:
    1. –ò—â–µ–º –Ω–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞ –∏–ª–∏ —Å—Ç—Ä–æ–∫—É "–Ω–æ–º–µ—Ä + —Ç–µ–∫—Å—Ç"
    2. –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞ –¥–æ –ø–µ—Ä–≤–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
    3. –°–æ–±–∏—Ä–∞–µ–º 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–∞
    4. –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —Ç–µ–º—É
    """
    lines = text.splitlines()
    tasks: list[ParsedTask] = []
    current_topic = "–ì–µ–æ–≥—Ä–∞—Ñ–∏—è"
    
    i = 0
    while i < len(lines):
        raw = lines[i]
        line = normalize_space(raw)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        if not line:
            i += 1
            continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–µ–º—É
        if is_topic_line(line):
            current_topic = line
            i += 1
            continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—Ç—Ä–æ–∫—É "–Ω–æ–º–µ—Ä + —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞"
        match_start = match_question_start(line)
        if match_start:
            number, q_first = match_start
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º inline –æ–ø—Ü–∏–∏ –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏
            q_first_clean, inline_opts = extract_options_from_raw_line(raw)
            if inline_opts:
                # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º q_first –±–µ–∑ inline –æ–ø—Ü–∏–π
                match_start_clean = match_question_start(q_first_clean)
                if match_start_clean:
                    q_first = match_start_clean[1]
            
            q_lines = [q_first]
            i += 1
            
            # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞
            options: dict[str, str] = inline_opts.copy()
            
            while i < len(lines) and len(options) < 4:
                raw2 = lines[i]
                line2 = normalize_space(raw2)
                
                if not line2:
                    i += 1
                    continue
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞
                if is_option_line(line2):
                    break
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π –Ω–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞
                if is_question_number_line(line2) or match_question_start(line2):
                    break
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —Ç–µ–º—É
                if is_topic_line(line2):
                    current_topic = line2
                    i += 1
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º inline –æ–ø—Ü–∏–∏
                cleaned, opts = extract_options_from_raw_line(raw2)
                if opts:
                    options.update(opts)
                    if cleaned:
                        q_lines.append(cleaned)
                else:
                    q_lines.append(line2)
                
                i += 1
            
            # –°–æ–±–∏—Ä–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
            while i < len(lines) and len(options) < 4:
                raw3 = lines[i]
                line3 = normalize_space(raw3)
                
                if not line3:
                    i += 1
                    continue
                
                # –ü–∞—Ä—Å–∏–º –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞
                m = re.match(r"^\s*([ABCD–ê–í–°Dabcd])\)\s*(.+)$", raw3)
                if m:
                    letter = m.group(1).upper()
                    letter = _CYR_TO_LAT.get(letter, letter)
                    if letter in ("A", "B", "C", "D"):
                        options[_LETTER_TO_NUMBER[letter]] = normalize_space(m.group(2))
                    i += 1
                    continue
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å - –≤—ã—Ö–æ–¥–∏–º
                if is_question_number_line(line3) or match_question_start(line3):
                    break
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —Ç–µ–º—É
                if is_topic_line(line3):
                    break
                
                i += 1
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–¥–∞—á—É
            question = normalize_space(" ".join(q_lines))
            if question and len(options) == 4:
                tasks.append(ParsedTask(
                    number=number,
                    question=question,
                    options=options,
                    topic=current_topic,
                ))
            continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞
        num_only = is_question_number_line(line)
        if num_only is not None:
            number = num_only
            i += 1
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞
            q_lines: list[str] = []
            options: dict[str, str] = {}
            
            while i < len(lines) and len(options) < 4:
                raw4 = lines[i]
                line4 = normalize_space(raw4)
                
                if not line4:
                    i += 1
                    continue
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞
                if is_option_line(line4):
                    break
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π –Ω–æ–º–µ—Ä
                if is_question_number_line(line4) or match_question_start(line4):
                    break
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —Ç–µ–º—É
                if is_topic_line(line4):
                    current_topic = line4
                    i += 1
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º inline –æ–ø—Ü–∏–∏
                cleaned, opts = extract_options_from_raw_line(raw4)
                if opts:
                    options.update(opts)
                    if cleaned:
                        q_lines.append(cleaned)
                else:
                    q_lines.append(line4)
                
                i += 1
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
            while i < len(lines) and len(options) < 4:
                raw5 = lines[i]
                line5 = normalize_space(raw5)
                
                if not line5:
                    i += 1
                    continue
                
                m = re.match(r"^\s*([ABCD–ê–í–°Dabcd])\)\s*(.+)$", raw5)
                if m:
                    letter = m.group(1).upper()
                    letter = _CYR_TO_LAT.get(letter, letter)
                    if letter in ("A", "B", "C", "D"):
                        options[_LETTER_TO_NUMBER[letter]] = normalize_space(m.group(2))
                    i += 1
                    continue
                
                # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å
                if is_question_number_line(line5) or match_question_start(line5):
                    break
                
                if is_topic_line(line5):
                    break
                
                i += 1
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–¥–∞—á—É
            question = normalize_space(" ".join(q_lines))
            if question and len(options) == 4:
                tasks.append(ParsedTask(
                    number=number,
                    question=question,
                    options=options,
                    topic=current_topic,
                ))
            continue
        
        i += 1
    
    return tasks


def parse_geography_answers(text: str) -> dict[int, str]:
    """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ Geography_tj_key.pdf
    
    –§–æ—Ä–º–∞—Ç: –æ—á–µ—Ä–µ–¥—å –Ω–æ–º–µ—Ä–æ–≤, –∑–∞—Ç–µ–º –æ—á–µ—Ä–µ–¥—å –±—É–∫–≤
    77
    78
    79
    ...
    C
    C
    A
    ...
    """
    answers: dict[int, str] = {}
    pending_numbers: deque[int] = deque()
    
    lines = text.splitlines()
    
    # –ò—â–µ–º –Ω–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–æ–≤
    start_idx = 0
    for idx, line in enumerate(lines):
        if '–ö–ê–õ–ò–î“≤–û–ò' in line or '–î–£–†–£–°–¢' in line:
            start_idx = idx + 1
            break
    
    lines = lines[start_idx:]
    
    for raw_line in lines:
        line = raw_line.strip()
        
        if not line:
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
        if line in ['.tj', '—Å–æ –†–û', '–º–æ –ô', '–Ω–∞ –ì –û', '–∏ –ù', 'w !', 'w', '.n', 'tc', '–î–∞', '—Ä']:
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
        if any(x in line for x in ['–ì–µ–æ–≥—Ä–∞—Ñ–∏—è', '–°–∞“≥–∏—Ñ–∞–∏', '–ò–ú–î', '–ö–ê–õ–ò–î“≤–û–ò', '–°–ê–í–û–õ–£', '–ú–ê–°–™–ê–õ–ê“≤–û']):
            continue
        
        # –ù–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞
        if re.fullmatch(r'\d{1,4}', line):
            pending_numbers.append(int(line))
            continue
        
        # –ë—É–∫–≤–∞ –æ—Ç–≤–µ—Ç–∞
        if re.fullmatch(r'[ABCD–ê–í–°D]', line):
            if pending_numbers:
                n = pending_numbers.popleft()
                letter = line.upper()
                letter = _CYR_TO_LAT.get(letter, letter)
                if letter in _LETTER_TO_NUMBER:
                    answers[n] = _LETTER_TO_NUMBER[letter]
            continue
    
    return answers


def generate_fixture(tasks: list[ParsedTask], answers: dict[int, str]) -> list[dict]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Django fixture"""
    fixture = []
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ ID –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö fixture —Ñ–∞–π–ª–æ–≤
    max_subject_id = 0
    max_topic_id = 0
    max_task_id = 0
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ fixture —Ñ–∞–π–ª—ã
    for fixture_file in ["tjk_data.json", "geography_data.json"]:
        if Path(fixture_file).exists():
            try:
                with open(fixture_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                    for item in existing_data:
                        if item['model'] == 'core.subject':
                            max_subject_id = max(max_subject_id, item['pk'])
                        elif item['model'] == 'core.topic':
                            max_topic_id = max(max_topic_id, item['pk'])
                        elif item['model'] == 'core.task':
                            max_task_id = max(max_task_id, item['pk'])
            except:
                pass
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å–≤–æ–±–æ–¥–Ω—ã–µ ID
    subject_id = max_subject_id + 1
    topic_pk = max_topic_id
    task_pk = max_task_id
    
    # –ü—Ä–µ–¥–º–µ—Ç –ì–µ–æ–≥—Ä–∞—Ñ–∏—è
    fixture.append({
        "model": "core.subject",
        "pk": subject_id,
        "fields": {
            "title": "–ì–µ–æ–≥—Ä–∞—Ñ–∏—è",
            "icon": "üåç",
            "color": "#10B981"
        }
    })
    
    # –¢–µ–º—ã
    topics_map: dict[str, int] = {}
    
    for task in tasks:
        if task.topic and task.topic not in topics_map:
            topics_map[task.topic] = topic_pk
            fixture.append({
                "model": "core.topic",
                "pk": topic_pk,
                "fields": {
                    "subject": subject_id,
                    "title": task.topic,
                    "order": len(topics_map),
                    "is_locked": False
                }
            })
            topic_pk += 1
    
    # –ó–∞–¥–∞—á–∏
    for task in tasks:
        task_pk += 1
        correct_answer = answers.get(task.number)
        if not correct_answer:
            print(f"‚ö†Ô∏è  –ù–µ—Ç –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ {task.number}")
            continue
        
        topic_id = topics_map.get(task.topic)
        
        fixture.append({
            "model": "core.task",
            "pk": task_pk,
            "fields": {
                "subject": subject_id,
                "topic": topic_id,
                "question": task.question,
                "options": task.options,
                "correct_answer": correct_answer,
                "difficulty": 1,
                "order": task.number
            }
        })
    
    return fixture


def main():
    print("üåç –ü–∞—Ä—Å–∏–Ω–≥ –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏ (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)...")
    print()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
    print("üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Geography_tj.pdf...")
    tasks_text = run_pdftotext(Path("A3-2_Geography_tj.pdf"), use_layout=True)
    
    print("üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Geography_tj_key.pdf...")
    answers_text = run_pdftotext(Path("A3-2_Geography_tj_key.pdf"), use_layout=False)
    
    # –ü–∞—Ä—Å–∏–º
    print("\nüîç –ü–∞—Ä—Å–∏–Ω–≥ –≤–æ–ø—Ä–æ—Å–æ–≤...")
    tasks = parse_geography_tasks(tasks_text)
    print(f"   –ù–∞–π–¥–µ–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(tasks)}")
    
    print("\nüîç –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤...")
    answers = parse_geography_answers(answers_text)
    print(f"   –ù–∞–π–¥–µ–Ω–æ –æ—Ç–≤–µ—Ç–æ–≤: {len(answers)}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    topics_count: dict[str, int] = {}
    for task in tasks:
        topics_count[task.topic] = topics_count.get(task.topic, 0) + 1
    
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–º–∞–º:")
    for topic, count in sorted(topics_count.items()):
        print(f"   {topic}: {count} –≤–æ–ø—Ä–æ—Å–æ–≤")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º fixture
    print("\nüì¶ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è fixture...")
    fixture = generate_fixture(tasks, answers)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_file = "geography_data.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(fixture, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! Fixture —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_file}")
    print(f"   –ü—Ä–µ–¥–º–µ—Ç–æ–≤: 1")
    print(f"   –¢–µ–º: {len(topics_count)}")
    print(f"   –ó–∞–¥–∞—á: {len([item for item in fixture if item['model'] == 'core.task'])}")
    print()
    print("üì• –î–ª—è –∏–º–ø–æ—Ä—Ç–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö:")
    print(f"   python manage.py loaddata {output_file}")


if __name__ == '__main__':
    main()
